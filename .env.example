# -----------------------------------------------------------------------------
# RAG API â€“ copy to .env and adjust.
# -----------------------------------------------------------------------------

# Qdrant vector DB
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION=rag_collection

# Embeddings: EMBEDDING_PROVIDER = "local" (sentence-transformers) or "openai"
EMBEDDING_PROVIDER=local
# For local: model name and dim (e.g. bge-small-en = 384)
EMBEDDING_MODEL_NAME=BAAI/bge-small-en
EMBEDDING_DIM=384
# For openai: set OPENAI_API_KEY and OPENAI_EMBEDDING_MODEL; EMBEDDING_DIM must match (e.g. 1536 for text-embedding-3-small)
# OPENAI_API_KEY=sk-...
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Ollama LLM
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral
OLLAMA_TIMEOUT=120

# Retrieval: number of chunks to fetch per query
RETRIEVAL_TOP_K=5
# Reranker: set to true to retrieve more then rerank (improves relevance)
RERANK_ENABLED=false
RERANK_INITIAL_K=20
# Reranker type: "keyword" (overlap) or "bm25" (hybrid sparse + vector via RRF)
RERANKER_TYPE=keyword

# Chunking
CHUNK_SIZE=512
CHUNK_OVERLAP=50
INGEST_BATCH_SIZE=32
# Chunker: "smart" (sentence-aware) or "paragraph"
CHUNKER_TYPE=smart
# Optional: restrict /ingest to paths under this directory (leave empty to allow any path)
# INGEST_ROOT=

# Optional: require X-API-Key header on /query and /ingest (leave empty to allow unauthenticated access)
# API_KEY=your-secret-key
# Optional: max requests per minute per API key or IP (0 = no limit)
# RATE_LIMIT_PER_MINUTE=60